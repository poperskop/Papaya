{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "428ae67c-102d-4f71-925c-0d56d5a92ddf",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "31df1f5b-2a45-45df-a8c1-17bd54dd57ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    EvalPrediction, \n",
    "    ViTImageProcessor,\n",
    "    ViTForImageClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from torch.nn import (\n",
    "    Linear,\n",
    "    Module, \n",
    "    CrossEntropyLoss\n",
    ")\n",
    "from typing import Optional\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d2b839-be6f-47c5-8016-6477672c2c4d",
   "metadata": {},
   "source": [
    "## Determine some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0bb13a45-c28a-4ba9-bd4b-ad403e27ccc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def seed_all(seed_value: int = 42) -> None:\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "\n",
    "SEED = 42\n",
    "seed_all(SEED)\n",
    "MODEL_NAME = 'WinKawaks/vit-tiny-patch16-224'\n",
    "DATA = 'papayas_links.csv'\n",
    "DEVICE =  'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15017bdc-0e4c-42d3-bcb8-a17181343edd",
   "metadata": {},
   "source": [
    "## Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3f259154-7177-4c4b-8819-d3fed9b44736",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(Dataset):\n",
    "    def __init__(self,\n",
    "                 df: pd.DataFrame,\n",
    "                 processor: ViTImageProcessor\n",
    "                ):\n",
    "        self.len = len(df)\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = df.path[index]\n",
    "        try:\n",
    "            img = processor(cv.imread(path), return_tensors=\"pt\")\n",
    "        except: raise ValueError(\n",
    "            f'this is problem {index}, {path}'\n",
    "        )\n",
    "        label = df.label[index]\n",
    "        return {\n",
    "            'labels': label,\n",
    "            'pixel_values': img['pixel_values'][0]\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class ClassificationMetrica:\n",
    "    \"\"\"\n",
    "    Class for computing metrics (sklearn, classification_report())\n",
    "    by EvalPrediction at training and evaluation stages.\n",
    "\n",
    "    Args:\n",
    "        id2label (dict): A dictionary where keys it's classes idx\n",
    "        and values it's classes names.\n",
    "    \"\"\"\n",
    "    def __init__(self, id2label: dict[int, str]):\n",
    "        self._id2label = id2label\n",
    "\n",
    "    def __get_target_names(self, preds: np.ndarray) -> list[str]:\n",
    "        unique_classes = np.unique(preds)\n",
    "        return [\n",
    "            self._id2label[idx]\n",
    "            for idx in unique_classes\n",
    "        ]\n",
    "\n",
    "    def _compute_metrics(self, labels: np.ndarray, preds: np.ndarray) -> dict:\n",
    "        target_names = self.__get_target_names(preds)\n",
    "        return classification_report(\n",
    "            labels, preds,\n",
    "            output_dict=True,\n",
    "            target_names=target_names\n",
    "        )\n",
    "\n",
    "    def _get_logs(self, metrics: dict) -> dict:\n",
    "        train_logs = {}\n",
    "        for main_key, main_item in metrics.items():\n",
    "            if main_key.isdigit():\n",
    "                main_key = self._id2label[int(main_key)]\n",
    "            if isinstance(main_item, dict):\n",
    "                main_item.pop(\"support\", None)\n",
    "                for key, value in main_item.items():\n",
    "                    train_logs[f\"{main_key}/{key}\"] = value\n",
    "            else:\n",
    "                train_logs[main_key] = main_item\n",
    "        return train_logs\n",
    "\n",
    "    def __call__(self, pred: EvalPrediction) -> dict[str, float]:\n",
    "        global predx\n",
    "        predx = pred\n",
    "        labels = pred.label_ids\n",
    "        logits = pred.predictions\n",
    "        preds = logits.argmax(-1)\n",
    "        metrics = self._compute_metrics(labels, preds)\n",
    "        logs = self._get_logs(metrics)\n",
    "        return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d4ea31-dd32-436b-8f17-8298ae09463a",
   "metadata": {},
   "source": [
    "## Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "54c5e423-2f14-4e98-a3f4-bbaab8074493",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Papaya(\n",
    "    Module,\n",
    "    PyTorchModelHubMixin\n",
    "):\n",
    "    def __init__(self, \n",
    "                 num_labels: Optional[int] = len(id2label), \n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.num_labels = num_labels\n",
    "        print(self.num_labels)\n",
    "        self.backbone = AutoModel.from_pretrained(MODEL_NAME)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classification_head = Linear(self.backbone.config.hidden_size, num_labels)\n",
    "        self.loss = CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, \n",
    "                pixel_values: torch.Tensor, \n",
    "                labels: Optional[torch.Tensor] = None\n",
    "                ) -> dict[str, torch.Tensor]:\n",
    "        outputs = self.backbone(pixel_values)\n",
    "        cls_embedding = outputs['pooler_output']\n",
    "    \n",
    "        logits = self.classification_head(cls_embedding)\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss = self.loss(logits, labels)\n",
    "            return {\n",
    "                \"loss\": loss, \n",
    "                \"logits\": logits\n",
    "            }\n",
    "        return {\n",
    "            \"logits\": logits\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c96d7a-e7a8-4270-ac1a-7d5e81707afb",
   "metadata": {},
   "source": [
    "## Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "40a59035-81bd-4b03-b11c-414d35a6fb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at WinKawaks/vit-tiny-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Papaya()\n",
    "processor = ViTImageProcessor.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a4d1986b-7066-4711-ae2e-29323a497b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Anthracnose', 1: 'fruit_fly', 2: 'healthy_guava'} {'Anthracnose': 0, 'fruit_fly': 1, 'healthy_guava': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "      <th>cluster</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101_unsharp_clahe_augmented_5.png</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>data\\test\\Anthracnose\\101_unsharp_clahe_augmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103_unsharp_clahe_augmented_7.png</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>data\\test\\Anthracnose\\103_unsharp_clahe_augmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107_unsharp_clahe_augmented_3.png</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>data\\test\\Anthracnose\\107_unsharp_clahe_augmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107_unsharp_clahe_augmented_6.png</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>data\\test\\Anthracnose\\107_unsharp_clahe_augmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108_unsharp_clahe_augmented_5.png</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>data\\test\\Anthracnose\\108_unsharp_clahe_augmen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           file_name  label cluster  \\\n",
       "0  101_unsharp_clahe_augmented_5.png      0    test   \n",
       "1  103_unsharp_clahe_augmented_7.png      0    test   \n",
       "2  107_unsharp_clahe_augmented_3.png      0    test   \n",
       "3  107_unsharp_clahe_augmented_6.png      0    test   \n",
       "4  108_unsharp_clahe_augmented_5.png      0    test   \n",
       "\n",
       "                                                path  \n",
       "0  data\\test\\Anthracnose\\101_unsharp_clahe_augmen...  \n",
       "1  data\\test\\Anthracnose\\103_unsharp_clahe_augmen...  \n",
       "2  data\\test\\Anthracnose\\107_unsharp_clahe_augmen...  \n",
       "3  data\\test\\Anthracnose\\107_unsharp_clahe_augmen...  \n",
       "4  data\\test\\Anthracnose\\108_unsharp_clahe_augmen...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA)\n",
    "label2id = {a: b for b, a in enumerate(df.label.unique())}\n",
    "id2label = {a: b for a, b in enumerate(df.label.unique())}\n",
    "print(id2label, label2id)\n",
    "df.label = df.label.map(lambda x: label2id[x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2d1c6bce-4023-42de-abe9-9ed20b1f7f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = DataSet(df.query('cluster == \"train\"').reset_index(), processor)\n",
    "\n",
    "val_df = DataSet(df.query('cluster == \"val\"').reset_index(), processor)\n",
    "\n",
    "test_df = DataSet(df.query('cluster == \"test\"').reset_index(), processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5f6f9fbf-7403-4dc0-b540-f55be4fbc424",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrica = ClassificationMetrica(id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4858ce3a-9959-4542-a759-2dc939c792c1",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "28e49b60-e28c-49ba-bdab-b6d5d9c69367",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-5\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"models/{MODEL_NAME}\",\n",
    "    num_train_epochs=3, \n",
    "    per_device_train_batch_size=128, \n",
    "    per_device_eval_batch_size=128,\n",
    "    weight_decay=0.015,\n",
    "    logging_dir=None,\n",
    "    learning_rate=lr,\n",
    "    eval_strategy=\"steps\", \n",
    "    logging_strategy=\"steps\",\n",
    "    eval_steps=20,\n",
    "    logging_steps=20,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=30,\n",
    "    seed=SEED,\n",
    "    report_to=None, \n",
    "    warmup_ratio=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b2c8d9dd-806c-4af6-bd13-c9c0abf285ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 01:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Anthracnose/precision</th>\n",
       "      <th>Anthracnose/recall</th>\n",
       "      <th>Anthracnose/f1-score</th>\n",
       "      <th>Fruit Fly/precision</th>\n",
       "      <th>Fruit Fly/recall</th>\n",
       "      <th>Fruit Fly/f1-score</th>\n",
       "      <th>Healthy Guava/precision</th>\n",
       "      <th>Healthy Guava/recall</th>\n",
       "      <th>Healthy Guava/f1-score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro avg/precision</th>\n",
       "      <th>Macro avg/recall</th>\n",
       "      <th>Macro avg/f1-score</th>\n",
       "      <th>Weighted avg/precision</th>\n",
       "      <th>Weighted avg/recall</th>\n",
       "      <th>Weighted avg/f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.772000</td>\n",
       "      <td>0.391958</td>\n",
       "      <td>0.930728</td>\n",
       "      <td>0.990548</td>\n",
       "      <td>0.959707</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.842466</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.896689</td>\n",
       "      <td>0.878993</td>\n",
       "      <td>0.747172</td>\n",
       "      <td>0.759454</td>\n",
       "      <td>0.903252</td>\n",
       "      <td>0.896689</td>\n",
       "      <td>0.879010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.279200</td>\n",
       "      <td>0.169984</td>\n",
       "      <td>0.983271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991565</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.992424</td>\n",
       "      <td>0.925795</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.691489</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.960265</td>\n",
       "      <td>0.945223</td>\n",
       "      <td>0.894638</td>\n",
       "      <td>0.909953</td>\n",
       "      <td>0.963236</td>\n",
       "      <td>0.960265</td>\n",
       "      <td>0.957772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.132089</td>\n",
       "      <td>0.990637</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995296</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840426</td>\n",
       "      <td>0.913295</td>\n",
       "      <td>0.980132</td>\n",
       "      <td>0.973405</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957365</td>\n",
       "      <td>0.981127</td>\n",
       "      <td>0.980132</td>\n",
       "      <td>0.979528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=63, training_loss=0.39280575040786986, metrics={'train_runtime': 87.6114, 'train_samples_per_second': 90.639, 'train_steps_per_second': 0.719, 'total_flos': 0.0, 'train_loss': 0.39280575040786986, 'epoch': 3.0})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_df,\n",
    "    eval_dataset=val_df,\n",
    "    compute_metrics=metrica\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12aa3e7-005e-4482-9fda-f9d391957e19",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b781827e-83f7-4fe3-b8bc-5cffd8ec2623",
   "metadata": {},
   "source": [
    "We got high **precision** for healthy guava and high **recall** for else classes. Lets check the likage (It\\`s best to do at the begining, but i don\\`t get paid so didn`t bother)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5f87ca2c-d7f5-4ac3-a1d5-d5477919c434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1624"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated('file_name').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "002ac269-0639-4315-b2ed-c7334d4a54b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTModel(\n",
       "  (embeddings): ViTEmbeddings(\n",
       "    (patch_embeddings): ViTPatchEmbeddings(\n",
       "      (projection): Conv2d(3, 192, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): ViTEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x ViTLayer(\n",
       "        (attention): ViTSdpaAttention(\n",
       "          (attention): ViTSdpaSelfAttention(\n",
       "            (query): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (key): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (value): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ViTSelfOutput(\n",
       "            (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ViTIntermediate(\n",
       "          (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ViTOutput(\n",
       "          (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((192,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((192,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)\n",
       "  (pooler): ViTPooler(\n",
       "    (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4db1c7a-a5be-4330-b178-242ef220f875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
